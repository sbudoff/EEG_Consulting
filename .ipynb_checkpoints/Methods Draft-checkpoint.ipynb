{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d980920",
   "metadata": {},
   "source": [
    "# EEG Cannabis Sleep Consulting Project\n",
    "\n",
    "## Methods Daft\n",
    "\n",
    "This notebook contains the functions we used and brief descriptions of what they do and how we used them in our implementation.\n",
    "\n",
    "### Section 1: Library & Data Loading\n",
    "\n",
    "The dataset consists of two main file types, an edf trace file consisting of electrophysiology, and a rml containing metadata such as technician notes. Standard python libraries are used for data loading, visualization, and manipulation. Speciailized functions from the MNE library allow for reading and manipulation of the edf data. The main pages for these functions can be found here: \n",
    "https://docs.python.org/3/library/os.html\n",
    "https://mne.tools/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67399d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Loading\n",
    "import mne, os\n",
    "import xml.etree.ElementTree as ET\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37652695",
   "metadata": {},
   "source": [
    "The next cell sets up file path interogation using the os package. The file path leads to an edf file, which contains the signal data we want to read in as well as the rml containing important meta data. The os package is used to allow for greater flexibility and ultimately operating system agnosticism. \n",
    "Documentation: https://docs.python.org/3/library/os.path.html#module-os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08f943fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = os.path.join(os.getcwd(), 'Examples2024', '00000016-APDx20974') # this is an example participant ID\n",
    "data_path = os.path.join(data_root, '00000016-APDx20974[001].edf')\n",
    "meta_path = os.path.join(data_root, '00000016-APDx20974.rml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f3227f-5e81-4c5d-8273-72739f28c74e",
   "metadata": {},
   "source": [
    "#### Section 1.1: Metadata Loading\n",
    "\n",
    "Metadata associated with each recording is stored as .xml files. To interogate these in python the following functions were devised to convert a given .xml into a dictionary for native handling in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718a46a2-ab37-45bc-91aa-96b433f50b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_namespaces(file_path):\n",
    "    \"\"\"\n",
    "    Parses the XML file and extracts namespaces as a dictionary.\n",
    "    Namespaces in XML are declared in the root element or throughout the document.\n",
    "    \n",
    "    Args:\n",
    "    - file_path: Path to the XML file.\n",
    "    \n",
    "    Returns:\n",
    "    A dictionary with namespace prefixes as keys and URIs as values.\n",
    "    \"\"\"\n",
    "    namespaces = {}\n",
    "    for event, elem in ET.iterparse(file_path, events=('start-ns',)):\n",
    "        prefix, uri = elem\n",
    "        namespaces[prefix] = uri\n",
    "    return namespaces\n",
    "\n",
    "def xml_to_dict(element, namespaces):\n",
    "    \"\"\"\n",
    "    Recursively convert an XML element and its children into a dictionary.\n",
    "    \n",
    "    Args:\n",
    "    - element: The XML element to convert.\n",
    "    - namespaces: A dictionary of XML namespaces.\n",
    "    \n",
    "    Returns:\n",
    "    A dictionary representation of the XML element.\n",
    "    \"\"\"\n",
    "    # Base case: If the element has no children, return its text content\n",
    "    # or an empty string if the content is None.\n",
    "    if not list(element):  # Checks if the element has no children\n",
    "        return element.text or ''\n",
    "    \n",
    "    # Recursion: Convert children into dictionary entries\n",
    "    element_dict = {}\n",
    "    for child in element:\n",
    "        child_tag = child.tag.split('}')[-1]  # Removes the namespace URI if present\n",
    "        child_dict = xml_to_dict(child, namespaces)  # Recursive call\n",
    "        \n",
    "        # Handle cases where tags are repeated by aggregating them into lists\n",
    "        if child_tag in element_dict:\n",
    "            if not isinstance(element_dict[child_tag], list):\n",
    "                # Convert existing entry into a list\n",
    "                element_dict[child_tag] = [element_dict[child_tag]]\n",
    "            element_dict[child_tag].append(child_dict)\n",
    "        else:\n",
    "            element_dict[child_tag] = child_dict\n",
    "    \n",
    "    return element_dict\n",
    "\n",
    "def convert_rml_to_dict(metadata_path):\n",
    "    \"\"\"\n",
    "    Reads a .rml file, parses it, and converts it into a dictionary.\n",
    "    \n",
    "    Args:\n",
    "    - metadata_path: Path to the .rml file.\n",
    "    \n",
    "    Returns:\n",
    "    A dictionary representing the .rml file's structure.\n",
    "    \"\"\"\n",
    "    # Read and parse the .rml file\n",
    "    tree = ET.parse(metadata_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Generate namespaces dictionary automatically\n",
    "    namespaces = get_namespaces(metadata_path)\n",
    "\n",
    "    # Convert the root XML element to a dictionary\n",
    "    return xml_to_dict(root, namespaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db2916-84c7-43cc-bb2b-eac0002bce48",
   "metadata": {},
   "source": [
    "Example loading of an xml as a dictionary, and example useage of pythonic key-value interogation to extract important metadata related to estimating sleep onset time are displayed in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0530b892-473a-4e7f-8394-5baecda328c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaData Keys: dict_keys(['Patient', 'ChannelConfig', 'Acquisition', 'CustomEventTypeDefs', 'AcquisitionCommentDefs', 'ScoringData', 'AnalysisOptions', 'ReportCalcOptions', 'EventFilters', 'TrendChannelMappings'])\n",
      "\n",
      "Recording began at 2016-09-15T19:25:47, lights OFF at: 13350 seconds, lights ON at: 41112 seconds\n"
     ]
    }
   ],
   "source": [
    "# Example Loading\n",
    "xml_dict = convert_rml_to_dict(meta_path)\n",
    "print(f'MetaData Keys: {xml_dict.keys()}')\n",
    "\n",
    "# Example MetaData Extraction Via key-value assignment where values can be subdictionaries\n",
    "clock_t0 = xml_dict['Acquisition']['Sessions']['Session']['RecordingStart']\n",
    "t_lightOFF = xml_dict['Acquisition']['Sessions']['Session']['LightsOff']\n",
    "t_lightON = xml_dict['Acquisition']['Sessions']['Session']['LightsOn']\n",
    "print(f'\\nRecording began at {clock_t0}, lights OFF at: {t_lightOFF} seconds, lights ON at: {t_lightON} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a0a1e3",
   "metadata": {},
   "source": [
    "#### Section 1.2: E-Phys Loading\n",
    "The next cell loads the edf file of our choice (based on previous block), loads it into 'raw', and then prints information about it. We then select the channels we want to be able to plot/get information about. The channels we choose are loaded into 'selected_channels'. \n",
    "The package that lets us do this is the mne python package. The documentation can be seen here: \n",
    "https://mne.tools/stable/generated/mne.io.read_raw_edf.html\n",
    "https://mne.tools/stable/generated/mne.Info.html\n",
    "\n",
    "Sample channel loading and isolation implementation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d018c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/sam/Classes/Stats/Consulting/EEG_Consulting/Examples2024/00000016-APDx20974/00000016-APDx20974[001].edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 9235599  =      0.000 ... 46177.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_726429/2871810641.py:2: RuntimeWarning: Channel names are not unique, found duplicates for: {'Flow Patient'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(data_path, preload=True) # data path is the file's location\n"
     ]
    }
   ],
   "source": [
    "# Load an EDF file\n",
    "raw = mne.io.read_raw_edf(data_path, preload=True) # data path is the file's location\n",
    "\n",
    "# Print information about the file\n",
    "print(raw.info)\n",
    "\n",
    "# Print all channel names to review them\n",
    "print(raw.info['ch_names'])\n",
    "# the channel names tell us which signals we are looking at\n",
    "\n",
    "# Subset to only EEG Channels and print general data\n",
    "selected_channels = raw.pick(['EEG C3-A2', 'EEG C4-A1', 'EEG O1-A2', 'EEG O2-A1'])\n",
    "\n",
    "display(selected_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccd4ef4",
   "metadata": {},
   "source": [
    "Output: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c46149-c0d0-4db0-b324-ac4846203740",
   "metadata": {},
   "source": [
    "### Section 2: Data Cleaning\n",
    "Before analysis, the dataset must be first assessed for gross unuseability, and next subset to the time periods of interest.\n",
    "\n",
    "#### Section 2.1: Evaluation of Technician Notes\n",
    "Exploring the meta-data one will find comments and channel failure events. These can be assessed in one of two ways as demonstrated below. First, an automateable extraction of the comments into a list is performed. These results can be printed as demonstrated and a human expert can decide if the technician noted a signifigant technical failure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde84d0e-0744-48b3-bd35-3d69cf281687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relevant_annotations(scoring_data):\n",
    "    # Initialize containers for different types of annotations\n",
    "    channel_fail_events = []\n",
    "    comments_with_timestamps = {}\n",
    "    \n",
    "    # Check if 'Events' key exists in 'ScoringData'\n",
    "    if 'Events' in scoring_data and 'Event' in scoring_data['Events']:\n",
    "        for event in scoring_data['Events']['Event']:\n",
    "            # Extract ChannelFail events\n",
    "            if 'ChannelFail' in event and event['ChannelFail']:\n",
    "                channel_fail_events.append(event['ChannelFail'])\n",
    "            \n",
    "            # Extract other comments, like 'Comment' or specific conditions\n",
    "            # Assume 'timestamp' is the key where the timestamp is stored in each event\n",
    "            if 'Comment' in event and event['Comment']:\n",
    "                comment = event['Comment']\n",
    "                timestamp = event.get('timestamp', 'unknown')  # Provide a default value in case timestamp is missing\n",
    "                \n",
    "                # Check if this comment has already been recorded\n",
    "                if comment in comments_with_timestamps:\n",
    "                    # Append the new timestamp to the existing list for this comment\n",
    "                    comments_with_timestamps[comment].append(timestamp)\n",
    "                else:\n",
    "                    # Otherwise, start a new list with this timestamp\n",
    "                    comments_with_timestamps[comment] = [timestamp]\n",
    "    \n",
    "    return channel_fail_events, comments_with_timestamps\n",
    "\n",
    "# Try to see commentary in the file\n",
    "scoring_data = xml_dict.get('ScoringData', {})\n",
    "channel_fail_events, other_comments = extract_relevant_annotations(scoring_data)\n",
    "\n",
    "# Display the findings\n",
    "print(\"Channel Fail Events:\")\n",
    "for event in channel_fail_events:\n",
    "    print(f\"  - {event}\")\n",
    "\n",
    "print(\"\\nOther Comments:\")\n",
    "for comment in other_comments:\n",
    "    print(f\"  - {comment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d49f9d-24f2-4e20-8f66-d8c59100296b",
   "metadata": {},
   "source": [
    "Alternatively, if a LLM can be used to perfrom the same task, however, this raises additional concerns related to data passing through an insecure server, or a smaller LLM simply being incapable of effectively evaluating the notes in a consistent manner."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a01fed72-d52f-40b0-859e-454b591a56e2",
   "metadata": {},
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = f'Your task is to review comments made by an EEG technician during a patient\\'s sleep study to determine if leads fell off or if any of the noted observations similarly indicate a physical problem with the recording such as losing the electrophysiologic trace. Only reject datasets based on quipment related technical issues. The comments you have to evaluate are seperated by \" ; \" and are:/n/n{prompt_var}\\n\\nIt\\'s important to note that your evaluation should be based only on these comments. We specifically need to reject datasets if electordes fell off. Unless such an event is explicitly mentioned in the technician\\'s comments, it should not be assumed to have occurred./nPlease analyze the provided comments and respond with \"Data Good\" if you believe the dataset remains valid. If you find a technical issue within the comments that would invalidate the dataset, please respond with \"Data Rejected because [x]\", where \"[x]\" is your specific reason based on the comments provided.'\n",
    "\n",
    "temp = 10e-6 # This parameter should be as low as possible to minimize variations in prompt interpretation, however, setting 0 results in the model choosing for you\n",
    "model=\"gpt-4\"\n",
    "\n",
    "# Build completion objects \n",
    "completion = client.chat.completions.create( \n",
    "  model=model, \n",
    "  temperature=temp,\n",
    "  messages=[ \n",
    "    {\"role\": \"user\", \"content\": prompt} \n",
    "  ] \n",
    ") \n",
    "\n",
    "# Print the response to screen \n",
    "if completion.choices[0].message.content=='Data Good':\n",
    "    print('Inclusion in study validated by technician comments')\n",
    "else:\n",
    "    print(f'Technician comments indicate rejection. GPT4.0 Identified the following specific issue(s): {completion.choices[0].message.content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01496140-5fbd-4c81-8af8-d7725fa013cf",
   "metadata": {},
   "source": [
    "#### Section 2.2: Time Point Subsetting\n",
    "After Confirming a file is worth evaluating, the start time point should be used to discard pre-sleep recording data. The MNE interval function can then be used to extract and seperateley evaluate the first and second hour of sleep for the patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef78852d-16b5-48d9-a788-ef0546413a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting time must be established by medical expert, for demonstration purposes lights off time is used\n",
    "t_0 = int(t_lightOFF) # assume the time point is in seconds after onset of recording\n",
    "# Convert t_0 from seconds to samples to avoid inconsistencies\n",
    "sfreq = raw.info['sfreq']  # Sampling frequency\n",
    "t_0 = int(t_0 * sfreq)\n",
    "\n",
    "# Discard data before sleep onset\n",
    "raw.crop(tmin=t_0 / sfreq) # Note that we divide by sfreq again because raw.crop expects tmin and tmax in seconds, not samples.\n",
    "\n",
    "# Segment 1: First hour (0 to 3600 seconds)\n",
    "start_first_hour = 0  # Start immediately (assuming t_lightOFF adjustment is already made)\n",
    "end_first_hour = 3600  # End of first hour in seconds\n",
    "raw_first_hour = raw.copy().crop(tmin=start_first_hour, tmax=end_first_hour)\n",
    "data_first_hour, times_first_hour = raw_first_hour[:, :]\n",
    "\n",
    "# Segment 2: Second hour (3600 to 7200 seconds)\n",
    "start_second_hour = 3600  # Start of second hour in seconds\n",
    "end_second_hour = 7200  # End of second hour in seconds\n",
    "raw_second_hour = raw.copy().crop(tmin=start_second_hour, tmax=end_second_hour)\n",
    "data_second_hour, times_second_hour = raw_second_hour[:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107199e-07df-41c7-a1ef-7f64040bc49e",
   "metadata": {},
   "source": [
    "### Section 3: Computing Multitaper Spectra\n",
    "Computing and ploting of the multitaper spectral estimation method as previously used by Negar for all time points can be performed as demonstrated in the next cell. \n",
    "More info on Multitapers can be found here: https://ieeexplore.ieee.org/document/6767046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ecf9a7-d0f5-42cf-ae4f-fdaedcd48132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "fmin = 0.1\n",
    "fmax = 40\n",
    "\n",
    "# Compute PSD for the first hour\n",
    "psds_first_hour, freqs = mne.time_frequency.psd_array_multitaper(data_first_hour, sfreq=sfreq, fmin=fmin, fmax=fmax, adaptive=False, \n",
    "                                                                 normalization='length', verbose=True)\n",
    "\n",
    "# Compute PSD for the second hour\n",
    "psds_second_hour, freqs = mne.time_frequency.psd_array_multitaper(data_second_hour, sfreq=sfreq, fmin=fmin, fmax=fmax, adaptive=False, \n",
    "                                                                  normalization='length', verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51a79f",
   "metadata": {},
   "source": [
    "### Section 3: Data Visualization\n",
    "\n",
    "Loaded channels can be easily visualized as demonstrated in these plots of the first and second hour of sleep forthe subset eeg channels. \n",
    "Documentation: https://mne.tools/dev/generated/mne.io.Raw.html#mne.io.Raw.plot (see 'plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c2b730-930b-43f3-9674-90bf583119a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first hour\n",
    "raw_first_hour.plot(start=0, scalings=None, title='First Hour: EEG Channels')\n",
    "\n",
    "# Plot the second hour\n",
    "raw_second_hour.plot(start=0, scalings=None, title='Second Hour: EEG Channels')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b24cac",
   "metadata": {},
   "source": [
    "Output: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1950762",
   "metadata": {},
   "source": [
    "To viaulize the results of the multitaper spectra one can now use matplotlib directly as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735520b6-df9e-436e-959e-1b9c791b3dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['EEG C3-A2', 'EEG C4-A1', 'EEG O1-A2', 'EEG O2-A1']\n",
    "n_channels = len(channels)\n",
    "\n",
    "# Setup the figure and axes\n",
    "fig, axes = plt.subplots(nrows=n_channels, ncols=2, figsize=(12, 8))  # Adjust figsize as needed\n",
    "\n",
    "# Iterate over each channel\n",
    "for i, channel in enumerate(channels):\n",
    "    # First hour plot\n",
    "    axes[i, 0].semilogy(freqs, psds_first_hour[i].T, label=f'First Hour: {channel}')\n",
    "    axes[i, 0].set_xlabel('Frequency (Hz)')\n",
    "    axes[i, 0].set_ylabel('PSD (dB)')\n",
    "    axes[i, 0].set_title(f'First Hour: {channel}')\n",
    "    axes[i, 0].set_xlim([0.1, 40])\n",
    "    # axes[i, 0].legend()\n",
    "\n",
    "    # Second hour plot\n",
    "    axes[i, 1].semilogy(freqs, psds_second_hour[i].T, label=f'Second Hour: {channel}')\n",
    "    axes[i, 1].set_xlabel('Frequency (Hz)')\n",
    "    axes[i, 1].set_ylabel('PSD (dB)')\n",
    "    axes[i, 1].set_title(f'Second Hour: {channel}')\n",
    "    axes[i, 1].set_xlim([0.1, 40])\n",
    "    # axes[i, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee6910-ba75-4ef2-92fb-b031f8fa5937",
   "metadata": {},
   "source": [
    "## Section 4: Normalization of Multitaper spectra\n",
    "\n",
    "A simple and efficient method to normalize multiatper spectra power is to simply identify the maximum value observed for a given patient's EEG location during the recording session of interest, in this case the first and second hour of sleep. This maximum value can then simply be used to divide and thus normalize all observations for this channel such that the maximum value for all patients and all channesl is 1 and the minimum is zero. To do this a simple for loop was constructed as below. With the above visualization being recreated in matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4015411-5655-4e47-87e0-287fb4eec64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each array has a shape of (n_channels, n_freqs), for memory management zero vectors are preinitialized\n",
    "normalized_psds_first_hour = np.zeros_like(psds_first_hour)\n",
    "normalized_psds_second_hour = np.zeros_like(psds_second_hour)\n",
    "\n",
    "for i in range(len(channels)):  # Iterate over each channel\n",
    "    # Find the maximum PSD value for the current channel across both hours\n",
    "    max_value = max(np.max(psds_first_hour[i]), np.max(psds_second_hour[i]))\n",
    "    \n",
    "    # Normalize the PSD values by the maximum value\n",
    "    normalized_psds_first_hour[i] = psds_first_hour[i] / max_value\n",
    "    normalized_psds_second_hour[i] = psds_second_hour[i] / max_value\n",
    "\n",
    "# Setup the figure and axes for 4 rows (channels) and 1 column\n",
    "fig, axes = plt.subplots(nrows=len(channels), ncols=1, figsize=(10, 12))  # Adjust figsize as needed\n",
    "\n",
    "for i, channel in enumerate(channels):\n",
    "    # Plot the normalized PSD for the first hour with alpha adjustment\n",
    "    axes[i].semilogy(freqs, normalized_psds_first_hour[i].T, label='First Hour', alpha=0.7)\n",
    "    \n",
    "    # Plot the normalized PSD for the second hour with alpha adjustment\n",
    "    axes[i].semilogy(freqs, normalized_psds_second_hour[i].T, label='Second Hour', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Set plot attributes\n",
    "    axes[i].set_xlabel('Frequency (Hz)')\n",
    "    axes[i].set_ylabel('Normalized PSD')\n",
    "    axes[i].set_title(channel)\n",
    "    axes[i].set_xlim([0.1, 40])\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18a97a5",
   "metadata": {},
   "source": [
    "## Section 5: Headless Implementation\n",
    "\n",
    "The following function performs all of the above steps in a single function call for efficient and automated extraction of the Multitaper spectra for a given patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f517166e-cfd1-4578-acad-d06c49fff563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEG2Power(data_path, meta_path, \n",
    "              channels = ['EEG C3-A2', 'EEG C4-A1', 'EEG O1-A2', 'EEG O2-A1'], \n",
    "              fmin = 0.1, fmax = 40, visualize = False):\n",
    "    # Load the EDF file\n",
    "    raw = mne.io.read_raw_edf(data_path, preload=True) # data path is the file's location\n",
    "    # Load the xml meta data\n",
    "    xml_dict = convert_rml_to_dict(meta_path)\n",
    "    # Extract Lights off time\n",
    "    t_lightOFF = xml_dict['Acquisition']['Sessions']['Session']['LightsOff']\n",
    "    # Extract commentary in the metadata\n",
    "    scoring_data = xml_dict.get('ScoringData', {})\n",
    "    channel_fail_events, other_comments = extract_relevant_annotations(scoring_data)\n",
    "    # Display the warnings\n",
    "    print(\"Channel Fail Events:\")\n",
    "    for event in channel_fail_events:\n",
    "        print(f\"  - {event}\")\n",
    "    print(\"\\nOther Comments:\")\n",
    "    for comment in other_comments:\n",
    "        print(f\"  - {comment}\")\n",
    "    \n",
    "    # Subset to only EEG Channels and print general data\n",
    "    selected_channels = raw.pick(channels)\n",
    "    \n",
    "    # Starting time must be established by medical expert, for demonstration purposes lights off time is used\n",
    "    t_0 = int(t_lightOFF) # assume the time point is in seconds after onset of recording\n",
    "    # Convert t_0 from seconds to samples to avoid inconsistencies\n",
    "    sfreq = raw.info['sfreq']  # Sampling frequency\n",
    "    t_0 = int(t_0 * sfreq)\n",
    "    \n",
    "    # Discard data before sleep onset\n",
    "    raw.crop(tmin=t_0 / sfreq) # Note that we divide by sfreq again because raw.crop expects tmin and tmax in seconds, not samples.\n",
    "    \n",
    "    # Segment 1: First hour (0 to 3600 seconds)\n",
    "    start_first_hour = 0  # Start immediately (assuming t_lightOFF adjustment is already made)\n",
    "    end_first_hour = 3600  # End of first hour in seconds\n",
    "    raw_first_hour = raw.copy().crop(tmin=start_first_hour, tmax=end_first_hour)\n",
    "    data_first_hour, times_first_hour = raw_first_hour[:, :]\n",
    "    \n",
    "    # Segment 2: Second hour (3600 to 7200 seconds)\n",
    "    start_second_hour = 3600  # Start of second hour in seconds\n",
    "    end_second_hour = 7200  # End of second hour in seconds\n",
    "    raw_second_hour = raw.copy().crop(tmin=start_second_hour, tmax=end_second_hour)\n",
    "    data_second_hour, times_second_hour = raw_second_hour[:, :]\n",
    "    \n",
    "    \n",
    "    # Compute PSD for the first hour\n",
    "    psds_first_hour, freqs = mne.time_frequency.psd_array_multitaper(data_first_hour, sfreq=sfreq, fmin=fmin, fmax=fmax, adaptive=False, \n",
    "                                                                     normalization='length', verbose=True)\n",
    "    \n",
    "    # Compute PSD for the second hour\n",
    "    psds_second_hour, freqs = mne.time_frequency.psd_array_multitaper(data_second_hour, sfreq=sfreq, fmin=fmin, fmax=fmax, adaptive=False, \n",
    "                                                                      normalization='length', verbose=True)\n",
    "\n",
    "    # Each array has a shape of (n_channels, n_freqs), for memory management zero vectors are preinitialized\n",
    "    normalized_psds_first_hour = np.zeros_like(psds_first_hour)\n",
    "    normalized_psds_second_hour = np.zeros_like(psds_second_hour)\n",
    "    \n",
    "    for i in range(len(channels)):  # Iterate over each channel\n",
    "        # Find the maximum PSD value for the current channel across both hours\n",
    "        max_value = max(np.max(psds_first_hour[i]), np.max(psds_second_hour[i]))\n",
    "        \n",
    "        # Normalize the PSD values by the maximum value\n",
    "        normalized_psds_first_hour[i] = psds_first_hour[i] / max_value\n",
    "        normalized_psds_second_hour[i] = psds_second_hour[i] / max_value\n",
    "    \n",
    "        # Setup the figure and axes for 4 rows (channels) and 1 column\n",
    "        fig, axes = plt.subplots(nrows=len(channels), ncols=1, figsize=(10, 12))  # Adjust figsize as needed\n",
    "\n",
    "    if visualize:\n",
    "        for i, channel in enumerate(channels):\n",
    "            # Plot the normalized PSD for the first hour with alpha adjustment\n",
    "            axes[i].semilogy(freqs, normalized_psds_first_hour[i].T, label='First Hour', alpha=0.7)\n",
    "            \n",
    "            # Plot the normalized PSD for the second hour with alpha adjustment\n",
    "            axes[i].semilogy(freqs, normalized_psds_second_hour[i].T, label='Second Hour', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Set plot attributes\n",
    "            axes[i].set_xlabel('Frequency (Hz)')\n",
    "            axes[i].set_ylabel('Normalized PSD')\n",
    "            axes[i].set_title(channel)\n",
    "            axes[i].set_xlim([0.1, 40])\n",
    "            axes[i].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    return {\"Freqs\" : freqs,\n",
    "           \"Hour 1\" : normalized_psds_first_hour,\n",
    "           \"Hour 2\" : normalized_psds_second_hour}\n",
    "\n",
    "# Example Useage\n",
    "Normalized_dict = EEG2Power(data_path, meta_path, \n",
    "                              channels = ['EEG C3-A2', 'EEG C4-A1', 'EEG O1-A2', 'EEG O2-A1'], \n",
    "                              fmin = 0.1, fmax = 40, visualize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd3851-3c89-4f5c-8b0c-b0354644a704",
   "metadata": {},
   "source": [
    "## Section 6: Group Analysis\n",
    "The final section of this workflow extracts investigator derived experiemtnal notes for crawling through the experiemtnal data, performing the above computations, and then assiging the power spectra to the correct experimental groups.\n",
    "\n",
    "### Section 6.1: Dataframe Iteration\n",
    "This first function allows us to iterate through a dataframe and return the values in a specified column. In most cases, we use this to return a list of IDs associated with participants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c25da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterframe(frame, col):\n",
    "    temp = []\n",
    "    for item in frame[col]:\n",
    "        temp.append(item)\n",
    "    print(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd4205",
   "metadata": {},
   "source": [
    "Example implementation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2432f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>Subject's sex at birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-24 14:17:06.549</td>\n",
       "      <td>00000016-APDx20974</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-24 14:17:11.560</td>\n",
       "      <td>00000020-APDx20974</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-24 14:17:15.794</td>\n",
       "      <td>00000040-APDx20067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-24 14:17:20.771</td>\n",
       "      <td>00000057-APDx20067</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp                  ID Subject's sex at birth\n",
       "0 2024-02-24 14:17:06.549  00000016-APDx20974                      M\n",
       "1 2024-02-24 14:17:11.560  00000020-APDx20974                      F\n",
       "2 2024-02-24 14:17:15.794  00000040-APDx20067                      M\n",
       "3 2024-02-24 14:17:20.771  00000057-APDx20067                      F"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa3efd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000016-APDx20974', '00000020-APDx20974', '00000040-APDx20067', '00000057-APDx20067']\n"
     ]
    }
   ],
   "source": [
    "IDs = iterframe(df, 'ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f4fc5",
   "metadata": {},
   "source": [
    "### Section 6.2: Dataframe Filtration\n",
    "The next function is used to filter the dataset based on a specified value in a specified column. It returns a new dataframe that only contains rows that have the desired value. A function like this could be used to filter the dataset based on smoking/non-smoking status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95a0dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rows(frame, col, val):\n",
    "    temp = frame[frame[col] == val]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1440e00",
   "metadata": {},
   "source": [
    "Example implementation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53e563b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = extract_rows(df, 'Subject\\'s sex at birth', 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b19f28fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>Subject's sex at birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-24 14:17:06.549</td>\n",
       "      <td>00000016-APDx20974</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-24 14:17:15.794</td>\n",
       "      <td>00000040-APDx20067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp                  ID Subject's sex at birth\n",
       "0 2024-02-24 14:17:06.549  00000016-APDx20974                      M\n",
       "2 2024-02-24 14:17:15.794  00000040-APDx20067                      M"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94141dfa",
   "metadata": {},
   "source": [
    "### Section 6.3: Median Computation\n",
    "\n",
    "To be completed: We will take the median of a subset of the data so we can plot the median power at each frequency for comparison. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f672ca",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "We are missing a few functions because we had to show Dr. Kinney what we had done so far and get input based on how we were approaching the problem before we had everything we need. \n",
    "\n",
    "There is also potential that we need to implement another function that can filter out unwanted time segments in the data. Unwanted time segments could include times when the participant woke up during the night, for example. We are waiting to hear if these times have been removed from the data or not, and will proceed based on the response. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
